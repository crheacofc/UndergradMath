{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "### a) \n",
    "Find the polynomial of lowest degree that agrees with the function f (x) = cos x at the nodes $x_0 =0, x_1 =\\pi/4, \\ and \\ x_2 =3\\pi/4.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import pi,sqrt,cos\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import e\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the Lagrange Formula\n",
    "$$P_2(x)=y_1\\frac{(x-x_2)(x-x_3)}{(x_1-x_2)(x_1-x_3)}+y_2\\frac{(x-x_1)(x-x_3)}{(x_2-x_1)(x_2-x_3)}+y_3\\frac{(x-x_1)(x-x_2)}{(x_3-x_1)(x_3-x_2)}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_1 = 0, x_2 = \\pi/4,  x_3 = 3\\pi/4$\n",
    "\n",
    "$y_1 = cos(0) = 1, y_2 = cos(\\pi/4) = \\frac{\\sqrt{2}}{2}, y_3 = cos(3\\pi/4) = -\\frac{\\sqrt{2}}{2} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging this in we get, \n",
    "$$P_2(x) = 1\\frac{(x-\\pi/4)(x-3\\pi/4)}{(0-\\pi/4)(0-3\\pi/4)}+\\frac{\\sqrt{2}}{2}\\frac{(x-0)(x-3\\pi/4)}{(\\pi/4-0)(\\pi/4-3\\pi/4)}-\\frac{\\sqrt{2}}{2}\\frac{(x-0)(x-\\pi/4)}{(3\\pi/4-0)(3\\pi/4-\\pi/4)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5403796460924681 -0.5731591682507563 -0.3821061121671709\n"
     ]
    }
   ],
   "source": [
    "c_1 = 1/((-pi/4)*(-(3*pi)/4))\n",
    "c_2 = (sqrt(2))/(2*(pi/4)*(pi/4-3*pi/4))\n",
    "c_3 = -(sqrt(2))/(((3*pi)/4)*((3*pi)/4-pi/4))\n",
    "print(c_1,c_2,c_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_2(x) = .54037965(x-\\pi/4)(x-3\\pi/4)-0.573159183x(x-3\\pi/4)-0.382106112x(x-\\pi/4)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Without using the actual value of the cosine at any argument except the above three, use this polynomial to approximate cos(1), and compute an upper bound on the error in this approximation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are just going to calculate P_2(1)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximated value of cos(1) = 0.5380415712171481\n"
     ]
    }
   ],
   "source": [
    "P_2 = .54037965*(1-pi/4)*(1-3*pi/4)-0.573159183*(1)*(1-3*pi/4)-0.382106112*(1)*(1-pi/4)\n",
    "print(\"The approximated value of cos(1) = %s\"%(P_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to determine the error for our polynomial...\n",
    "$$f(x)-P_2(x) = \\frac{(x-0)(x-\\pi/4)(x-3\\pi/4)}{3!}f'''(c) $$\n",
    "where $0 \\leq c \\leq 3\\pi/4 $\n",
    "$$f(x)=cos(x) \\rightarrow f'(x)=-sin(c) \\rightarrow f''(x)=-cos(x) \\rightarrow f'''(x)=sin(x)$$\n",
    "\n",
    "Hence to maximize the error, we need to maximize the third derivative. This can be done by letting $c = 3\\pi/4$.\n",
    "Thus the error is,\n",
    "$$e(x)=\\left|\\frac{(x-0)(x-\\pi/4)(x-3\\pi/4)}{3!}\\frac{\\sqrt(2)}{2}\\right| $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03429960841005762\n"
     ]
    }
   ],
   "source": [
    "err_max = abs((sqrt(2)*(1-0)*(1-pi/4)*(1-3*pi/4))/(6*2))\n",
    "print(err_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the max error for x=1 is 0.03429960841005762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Compute the actual error in this approximation of cos(1), and compare to your result in part (b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002260734650991636"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(cos(1)-P_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we are happy because this is less than the max error so the $P_2(x)$ we estimated is correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "Two quantities x and y are known to be related by the form $y = ae^x + be^{âˆ’x}$. (Aside: this is true for example if they come from a solution of the differential\n",
    "equation d2y/dx2 = y).\n",
    "For the following six x values (known exactly), y values have been measured, with most of the inaccuracy in the y values just due to rounding, but with a mistake in recording one of the y values; this gives the following table of values:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdata = np.matrix([0,.2,.4,.6,.8,1.])\n",
    "ydata = np.matrix([4.3,4.1245,4.1146,4.1382,4.5964,5.107])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "Set up the least squares procedure for this pair of basis functions, and determine the best estimates of a and b in the least squares sense.\n",
    "\n",
    "$$Ax = b$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is matrix A: \n",
      " [[ 1.          1.        ]\n",
      " [ 1.22140276  0.81873075]\n",
      " [ 1.4918247   0.67032005]\n",
      " [ 1.8221188   0.54881164]\n",
      " [ 2.22554093  0.44932896]\n",
      " [ 2.71828183  0.36787944]]\n"
     ]
    }
   ],
   "source": [
    "A = np.matrix(np.zeros((6,2)))\n",
    "A[:,0] = np.exp(xdata.T)\n",
    "A[:,1] = np.exp(-xdata.T)\n",
    "print(\"Here is matrix A: \\n %s\"%(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our b matrix: \n",
      " [[ 4.3   ]\n",
      " [ 4.1245]\n",
      " [ 4.1146]\n",
      " [ 4.1382]\n",
      " [ 4.5964]\n",
      " [ 5.107 ]]\n"
     ]
    }
   ],
   "source": [
    "b = np.matrix(ydata.T)\n",
    "print(\"Here is our b matrix: \\n %s\"%(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our ATA matrix: \n",
      " [[ 20.37957107   6.        ]\n",
      " [  6.           2.75807502]]\n",
      "Here is our ATb matrix: \n",
      " [[ 47.12797122]\n",
      " [ 16.65010212]]\n"
     ]
    }
   ],
   "source": [
    "ATA = A.T.dot(A)\n",
    "ATb = A.T.dot(b)\n",
    "print(\"Here is our ATA matrix: \\n %s\"%(ATA))\n",
    "print(\"Here is our ATb matrix: \\n %s\"%(ATb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have the normal equations:\n",
    "$$ \\left[ \\begin{array}{cc} 20.37957107 & 6. \\\\ 6. & 2.75807502  \\end{array} \\right] \\left[\\begin{array}{c} x_1\\\\x_2\\end{array} \\right] = \\left[\\begin{array}{c} 47.12797122 \\\\16.65010212\\end{array} \\right] $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is  1.48858338542 and b is 2.79854671971\n"
     ]
    }
   ],
   "source": [
    "ATA_inverse = ATA.I\n",
    "x = ATA_inverse*(ATb)\n",
    "a_val = x[0,0]\n",
    "b_val = x[1,0]\n",
    "print(\"a is \",a_val,\"and b is\",b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1099d6908>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhJDCXUQkhBTuIiIh9P8BiT12l0ktrggAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x108c4f630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_stuff = np.linspace(0,1,100)\n",
    "def y(x):\n",
    "    return 1.48858338542*e**(x)+2.79854671971*e**(-x)\n",
    "plt.plot(xdata,ydata,\"o\",color=\"sage\")\n",
    "plt.plot(x_stuff,y(x_stuff),\"-\",color=\"aquamarine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Based on this plot I would say this is a good fit!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Check the accuracy by computing the error at each point, and using this, try to identify the point where the mistaken y value is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the accuracy we have to check the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01286989]\n",
      " [ 0.01508388]\n",
      " [ 0.01797258]\n",
      " [-0.11005078]\n",
      " [ 0.02602865]\n",
      " [ 0.03108303]]\n"
     ]
    }
   ],
   "source": [
    "## estimate array\n",
    "values = np.matrix([1.48858338542,2.79854671971])\n",
    "residual = b-A*values.T\n",
    "print(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we can see that the fourth $y$ value has the worst error (corresponding to $x=.06$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Propose a plausible replacement for the erroneous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.248250776452348"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y(.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the relationship between the two quantites the perfect $y$ value to choose would be $y=4.2483$. However stick with the appropriate error i would stick with an error between the two previous errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008056070000000002"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.02602865-0.01797258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.256306846452349"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.248250776452348+0.008056070000000002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best $y$ value to chose to go along with our errors would be $y=4.2563$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Problem 3\n",
    "### a)\n",
    "Derive the approximation of fâ€²(x) of the form\n",
    "fâ€²(a) â‰ˆ Af(a) + Bf(a + 2h) + Cf(a + 3h),\n",
    "that is best the sense of having the highest possible degree of precision, p.\n",
    "(Note that the value at a + h is missing!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we are going to do the degree of precision trik to solve for the unknown coefficients\n",
    "We are going to guess that $f'(x)=Af(a)+Bf(a+2h)+Cf(a+3h)$.\n",
    "\n",
    "\n",
    "$\\underline{n=0}: f(x)=1 \\rightarrow f'(a) = 0 = A+B+C$\n",
    "\n",
    "$\\underline{n=1}: f(x)=x-a \\rightarrow f'(a) = 1 = 2hB+3hC $\n",
    "\n",
    "$\\underline{n=2}: f(x)=(x-a)^2 \\rightarrow f'(a)=0 = 4hB+9hC \\rightarrow C=\\frac{-4}{9}B $\n",
    "Hence after some solving we have,\n",
    "$$A=\\frac{-5}{6h} $$\n",
    "\n",
    "$$B=\\frac{3}{2h} $$\n",
    "\n",
    "$$C=\\frac{-2}{3h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence $$f'(x) \\approx \\frac{-5}{6h}f(a)+\\frac{3}{2h}f(a+2h)-\\frac{2}{3h}f(a+3h) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{n=3}: f(x)=(x-a)^3 \\rightarrow f'(a)=0 = 8hB+27hC \\rightarrow C=\\frac{-8}{27}B $\n",
    "which is not the same as $\\frac{-4}{9}$ so it does not work.\n",
    "\n",
    "Therefore we have a degree of precision 2!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Using Taylor polynomials of degree p with error term, verify that this approximation has error $O(h^p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have a degree of precision 2 lets check out a taylor polynomail of degree two with its error term.\n",
    "$$f(a+2h) = f(a) + 2hf'(a)+2h^2f''(a)+\\frac{8}{6}h^3f'''(c_1) $$ \n",
    "$$f(a+2h) = f(a) + 3hf'(a)+\\frac{9}{2}h^2f''(a)+\\frac{27}{6}h^3f'''(c_2) $$ \n",
    "\n",
    "Thus we have, \n",
    "$$\\frac{-5f(a)+9f(a)+18hf'(a)+18h^2f''(a)+12h^3f'''(c_1) -4f(a)-12hf'(a)-18h^2f''(a)-18h^3f'''(c_2)}{6h}$$\n",
    "which becomes\n",
    "$$\\frac{6hf'(a)+12h^3f'''(c_1)-18h^3f'''(c_2)}{6h} = f'(a)+(2f'''(c_1)-3f'''(c_2))h^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we have an error of $h^2$ as required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "The composite Simpsonâ€™s rule (which is fourth order accurate) has been used to\n",
    "approximate a definite integral $I=\\int^b_a f(x)dx$ with 10 and 20 intervals, giving the \n",
    "$$S_{10} = 7.38084362852$$\n",
    "$$S_{20} = 7.35531055134$$\n",
    "\n",
    "\n",
    "### a)\n",
    "Use Richardson extrapolation to get a better approximation to the value $I$ of\n",
    "this integral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation for Richardson extrapolation is \n",
    "$$\\frac{2^nF(h/2)-F(h)}{2^n-1}$$\n",
    "Hence since we have a fourth order approximation when we apply Richardson extrapolation we get,\n",
    "$$\\frac{2^4S_{10}-\n",
    "S_{20}}{2^4-1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we run Richardson extrapolation on this we get 7.353608346194666\n"
     ]
    }
   ],
   "source": [
    "S_10 = 7.38084362852\n",
    "S_20 = 7.35531055134\n",
    "R_e_1020 = (2**4*S_20-S_10) /(2**4-1)\n",
    "print(\"When we run Richardson extrapolation on this we get %s\"%(R_e_1020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Give a practical estimate of the error in this approximation of the integral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to approximate an error when you dont know the actual function that you are integrating is to take a look at the successive values given from new n-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example the most practical estimate of error between S_10 and S_20 is just: 0.02553307718000042\n",
      "For example the most practical estimate of error between S_20 and Richardson extrapolated value is just: 0.0017022051453334797\n"
     ]
    }
   ],
   "source": [
    "err = abs(S_20-S_10)\n",
    "err_re = abs(R_e_1020-S_20)\n",
    "print(\"For example the most practical estimate of error between S_10 and S_20 is just: %s\"%(err))\n",
    "print(\"For example the most practical estimate of error between S_20 and Richardson extrapolated value is just: %s\"%(err_re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "Given the extra information that $S_{60} = 7.35439923178$, use Richardson extrap- olation with S20 and S60 to get another, hopefully even more accurate approximation of the integral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we run Richardson extrapolation on this we get 7.354338477142667\n"
     ]
    }
   ],
   "source": [
    "S_60 = 7.35439923178\n",
    "R_e_2060 = (2**4*S_60-S_20) /(2**4-1)\n",
    "print(\"When we run Richardson extrapolation on this we get %s\"%(R_e_2060))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error is approximately 6.075463733345998e-05\n"
     ]
    }
   ],
   "source": [
    "err_60_re = abs(R_e_2060-S_60)\n",
    "print(\"The error is approximately %s\"%(err_60_re))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
